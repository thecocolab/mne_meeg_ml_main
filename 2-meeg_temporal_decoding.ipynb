{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate statistics (decoding / MVPA) on M/EEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Code source : Alexandre Gramfort, Richard Höchenberge \n",
    " Modified by Annalisa Pascarella, Vanessa Hadid`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding in MNE largely follows the machine learning API of the [`scikit-learn`](https://scikit-learn.org/stable/) package. We'll learn how to decode M/EEG evoked activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the log-level to 'WARNING' so the output is less verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the [`sample`](https://mne.tools/stable/documentation/datasets.html#sample-dataset) dataset. It's the same dataset of previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mne.datasets import sample\n",
    "data_path = sample.data_path()\n",
    "\n",
    "raw_fname = os.path.join(data_path, 'MEG/sample/sample_audvis_filt-0-40_raw.fif')\n",
    "print(raw_fname)\n",
    "raw = mne.io.read_raw_fif(raw_fname, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-pass filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw.filter(l_freq=1, h_freq=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the `auditory left` and `auditory right` stimuli. Let's extract the events and create the `Epochs` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events = mne.find_events(raw, stim_channel='STI 014', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = {'aud_l': 1, 'aud_r': 2}  # event trigger and conditions\n",
    "fig = mne.viz.plot_events(events, sfreq=raw.info['sfreq'],\n",
    "                          first_samp=raw.first_samp, event_id=event_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define epochs parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmin = -0.1  # start of each epoch (in seconds)\n",
    "tmax = 0.4   # end of each epoch\n",
    "baseline = None  # no baseline correction, data were high-pass filtered\n",
    "\n",
    "reject = dict(eeg=80e-6, eog=40e-6)\n",
    "picks = mne.pick_types(raw.info, eeg=True, meg=True,\n",
    "                       eog=True, stim=False, exclude='bads')\n",
    "\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True,\n",
    "                    picks=picks, baseline=baseline,\n",
    "                    reject=reject, preload=True)  # with preload\n",
    "\n",
    "print(epochs.get_data(copy=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatio-temporal decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can discriminate experimental conditions from single trials. \\\n",
    "To keep chance level at 50% accuracy, we first equalize the number of epochs in each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs.equalize_event_counts(event_id)\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classifier takes as input an `X` and returns `y` (0 or 1). Here `X` will be the data at each time point on all gradiometers (hence the term multivariate). We want to train our model to discriminate between the  `auditory left` and the `auditory right` trials.\n",
    "\n",
    "We try to find a discriminative pattern between the two conditions to predict the class.\n",
    "\n",
    "For classification we will use the scikit-learn package (http://scikit-learn.org/) and MNE functions.\n",
    "\n",
    "Let's first create the response vector, `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.empty(len(epochs.events), dtype=int)\n",
    "idx_auditory_left = epochs.events[:, 2] == event_id['aud_l']\n",
    "idx_auditory_right = epochs.events[:, 2] == event_id['aud_r']\n",
    "y[idx_auditory_left] = 0\n",
    "y[idx_auditory_right] = 1\n",
    "\n",
    "y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the input matrix, `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epochs.copy().pick_types(meg='grad').get_data()\n",
    "X.shape  # n_epochs x n_chs x n_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X.reshape(108, -1)\n",
    "XX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we estimate the accuracy of a [`Logistic Regression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier by splitting the data, fitting a model and computing the score 5 consecutive times (with different splits each time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')  # liblinear is the algorithm used to fit the model\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "clf = make_pipeline(StandardScaler(), logreg)\n",
    "\n",
    "scores = cross_val_score(clf, XX, y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "roc_auc_mean = np.mean(scores)\n",
    "roc_auc_std = np.std(scores)\n",
    "\n",
    "print(f'CV scores: {scores}')\n",
    "print(f'Mean ROC AUC = {roc_auc_mean:.3f} (std: {roc_auc_std:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn [`Pipeline`](https://scikit-learn.org/stable/modules/compose.html#pipeline) can be used to chain multiple estimators into one. \\\n",
    "[`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) is a variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set. \\\n",
    "[`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) returns the array of scores of the estimator for each run of the cross validation. Here we use the Area Under the Curve (AUC) of the  [`Receiver Operating Characteristic (ROC)`](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py) curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use `mne.decoding` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from mne.decoding import Scaler, Vectorizer, cross_val_multiscore, LinearModel, get_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs_decoding = epochs.copy().pick_types(meg='grad')\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "clf = make_pipeline(Scaler(epochs_decoding.info),\n",
    "                    Vectorizer(), \n",
    "                    logreg)\n",
    "\n",
    "X = epochs_decoding.get_data()\n",
    "y = epochs_decoding.events[:, 2]\n",
    "\n",
    "scores = cross_val_multiscore(clf, X, y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "roc_auc_mean = np.mean(scores)\n",
    "roc_auc_std = np.std(scores)\n",
    "\n",
    "print(f'CV scores: {scores}')\n",
    "print(f'Mean ROC AUC = {roc_auc_mean:.3f} (std: {roc_auc_std:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`mne.decoding.Scaler`](https://mne.tools/stable/generated/mne.decoding.Scaler.html#mne.decoding.Scaler) scales each channel by estimating μ and σ using data from all time points and epochs. Using this class is different from directly applying [`sklearn.preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) that scales each classification feature, e.g. each time point for each channel, with mean and standard deviation computed across epochs. \\\n",
    "scikit-learn transformers and estimators generally expect 2D data (n_samples * n_features), whereas MNE transformers typically output data with a higher dimensionality (e.g. n_samples * n_channels * n_times). A [`Vectorizer`](https://mne.tools/stable/generated/mne.decoding.Vectorizer.html#mne.decoding.Vectorizer) transforms n-dimensional array into 2D array of n_samples by n_features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISES:</b>\n",
    "     <ul>\n",
    "      <li>Why do you get different results from above? </li>\n",
    "      <li>How does the choice of cross-validation affect the results? Hint: Change the random_state</li>\n",
    "      <li>Try a different cross-validtion object like scikit-learn KFold, StratifiedShuffleSplit</li>\n",
    "      <li>Try a different score in the cross_val_multiscore function</li>\n",
    "      <li>Which sensor types give the best classification scores? EEG, MEG gradiometers, MEG magnetometers?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous examples, we have trained a classifier to discriminate between experimentel conditions by using the spatio-temporal patterns of **entire trials**. The classifier was able to predict which activation pattern belonged to which condition. \n",
    "\n",
    "However, an interesting neuroscientific is: **Exactly *when* do the brain signals for two conditions differ?**\n",
    "\n",
    "We can try to answer this question by fitting a classifier **at every single time point.** If the classifier can successfully discriminate between the two conditions, we can conclude that the spatial activation patterns measured by the M/EEG sensors differed **at this time point**. \\\n",
    "This strategy consists in fitting a multivariate predictive model on each time instant and evaluating its performance at the same instant on new epochs. \n",
    "\n",
    "The [`mne.decoding.SlidingEstimator`](https://mne.tools/stable/generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator) will take as input a pair of features `X`\n",
    "and targets `y`, where `X`has more than 2 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from mne.decoding import SlidingEstimator\n",
    "\n",
    "X = epochs_decoding.get_data()\n",
    "y = epochs_decoding.events[:, 2]\n",
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                    logreg)\n",
    "\n",
    "time_decod = SlidingEstimator(clf, scoring='roc_auc', n_jobs=1, verbose=True)\n",
    "scores = cross_val_multiscore(time_decod, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "# Mean scores across cross-validation splits, for each time point.\n",
    "mean_scores = np.mean(scores, axis=0)\n",
    "\n",
    "# Mean score across all time points.\n",
    "mean_across_all_times = np.mean(scores)\n",
    "print(f'Mean CV score across all time points: {mean_across_all_times:.3f}')\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs.times, mean_scores, label='score')\n",
    "ax.axhline(0.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Mean ROC AUC')\n",
    "ax.legend()\n",
    "ax.axvline(0, color='k', linestyle='-')\n",
    "ax.set_title('Sensor space decoding');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding source space data\n",
    "\n",
    "Now, we want to perform decoding of MEG data in the source space. This involes to solve the ill-posed MEG inverse problem. We apply the pre computed inverse operator to single trials and use as inverse method dSPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.minimum_norm import apply_inverse_epochs, read_inverse_operator\n",
    "\n",
    "subjects_dir = data_path / \"subjects\"\n",
    "fname_cov = data_path / \"MEG/sample/sample_audvis-cov.fif\"\n",
    "fname_inv = data_path / \"MEG/sample/sample_audvis-meg-oct-6-meg-inv.fif\"\n",
    "\n",
    "epochs_meg = epochs.copy().pick_types(meg=True)\n",
    "\n",
    "snr = 3.0\n",
    "\n",
    "noise_cov = mne.read_cov(fname_cov)\n",
    "inverse_operator = read_inverse_operator(fname_inv)\n",
    "\n",
    "stcs = apply_inverse_epochs(\n",
    "    epochs_meg,\n",
    "    inverse_operator,\n",
    "    lambda2=1.0 / snr**2,\n",
    "    verbose=False,\n",
    "    method=\"dSPM\",\n",
    "    pick_ori=\"normal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stcs` is a list of the reconstructed time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcs[0].rh_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve source space data into an array\n",
    "X = np.array([stc.data for stc in stcs])\n",
    "y = epochs.events[:, 2]\n",
    "\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here univariate feature selection is employed for speed purposes to confine the classification to a small number of potentially relevant features. The classifier then is trained to selected features of epochs in source space.\n",
    "\n",
    "We perform decoding at each time point in source space using a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# prepare a series of classifier applied at each time sample\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(),  # z-score normalization\n",
    "    SelectKBest(f_classif, k=500),  # select features for speed\n",
    "    LinearModel(LogisticRegression(C=1, solver=\"liblinear\")),\n",
    ")\n",
    "time_decod = SlidingEstimator(clf, scoring=\"roc_auc\")\n",
    "\n",
    "# Run cross-validated decoding analyses:\n",
    "scores = cross_val_multiscore(time_decod, X, y, cv=5, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average decoding scores of 5 splits\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(epochs.times, scores.mean(0), label=\"score\")\n",
    "ax.axhline(0.5, color=\"k\", linestyle=\"--\", label=\"chance\")\n",
    "ax.axvline(0, color=\"k\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_decod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fitting needs not be cross validated because the weights are based on the training sets\n",
    "time_decod.fit(X, y)\n",
    "\n",
    "# Retrieve patterns after inversing the z-score normalization step:\n",
    "patterns = get_coef(time_decod, \"patterns_\", inverse_transform=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stc = stcs[0]  # for convenience, lookup parameters from first stc\n",
    "vertices = [stc.lh_vertno, stc.rh_vertno]  # empty array for right hemi\n",
    "stc_feat = mne.SourceEstimate(\n",
    "    np.abs(patterns),\n",
    "    vertices=vertices,\n",
    "    tmin=stc.tmin,\n",
    "    tstep=stc.tstep,\n",
    "    subject=\"sample\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the patterns on source space you should install pyvistaqt and nibabel packages: \\\n",
    "\n",
    "`pip install pyvistaqt` and  `pip install nibabel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = stc_feat.plot(\n",
    "    hemi='both',\n",
    "    views=[\"lat\"],\n",
    "    transparent=True,\n",
    "    initial_time=0.1,\n",
    "    time_unit=\"s\",\n",
    "    subjects_dir=subjects_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISES:</b>\n",
    "     <ul>\n",
    "      <li>Plot the decoding score over time for the different channel types.</li>\n",
    "         <li> Do a decoding on source space </li>   \n",
    "      <li>Do a decoding over time on the SPM `face` dataset to see if you can classify `face` vs. `scrambled face`.</li>\n",
    "         <li>Do a generalization over time analysis.\n",
    "</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Access the `face` dataset via:\n",
    "\n",
    "    ```\n",
    "    from mne.datasets import spm_face\n",
    "    data_path = spm_face.data_path()\n",
    "\n",
    "    raw_fname = os.path.join(data_path, 'MEG/spm/SPM_CTF_MEG_example_faces1_3D.ds')\n",
    "    raw = mne.io.read_raw_ctf(raw_fname, preload=True)\n",
    "    ```\n",
    "\n",
    "- The event IDs are:\n",
    "\n",
    "    ```\n",
    "    event_ids = {\"faces\": 1, \"scrambled\": 2}\n",
    "    ```\n",
    "\n",
    "See this online example for additional hints: https://mne.tools/stable/auto_examples/datasets/spm_faces_dataset.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> For more details look at the following tutorials: \n",
    "    <a href=\"https://mne.tools/stable/auto_tutorials/machine-learning/50_decoding.html\" target=\"_blank\">Decoding (MVPA)</a> and this book chapter:\n",
    "\n",
    "Jean-Rémi King, Laura Gwilliams, Chris Holdgraf, Jona Sassenhagen, Alexandre Barachant, Denis Engemann, Eric Larson, Alexandre Gramfort. Encoding and Decoding Neuronal Dynamics: Methodological Framework to Uncover the Algorithms of Cognition. 2018. https://hal.archives-ouvertes.fr/hal-01848442/\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d1899d3d453529ab54a548c453eb03872168ef6a9900e12952b62a455030e12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
