{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNE-Python: From raw data to epochs and evoked responses (ERF/ERP)\n",
    "\n",
    "`Authors:\n",
    " Annalisa Pascarella\n",
    " Vanessa Hadid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the mne package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "print(mne.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the logging level to 'warning' so the output will be less verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('warning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the [`sample`](https://mne.tools/stable/documentation/datasets.html#sample-dataset) dataset. It will be downloaded automatically (approx. 2 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.datasets import sample\n",
    "data_path = sample.data_path()\n",
    "\n",
    "raw_fname = os.path.join(data_path, 'MEG/sample/sample_audvis_filt-0-40_raw.fif')\n",
    "print(raw_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from file\n",
    "\n",
    "To see what a function does...use this notation!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.io.read_raw_fif?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_fif(raw_fname, preload=True)\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the [Raw](https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw) object displays some basic information like the total number of channels, the number of time points at which the data were sampled, total duration, and the approximate size in memory. \n",
    "\n",
    "Note that by default, the data will actually not be loaded into memory automatically to preserve memory. To actually load the data, we have to pass `preload=True`.\n",
    "\n",
    "Now let's look at the measurement info. There is also quite a lot of information stored in the `raw.info` attribute.  It will give details about:\n",
    "\n",
    "   - sampling rate\n",
    "   - filtering parameters\n",
    "   - available channel types\n",
    "   - bad channels\n",
    "   - etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`raw.info` is just a dictionary and like Python dictionaries has a `.keys()` method that shows all the available field names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(raw.info, dict)\n",
    "print(raw.info.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can access its elements this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['sfreq']  # Sampling frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['bads']  # list of marked bad channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the info dict we observe that data were already filtered.\n",
    "\n",
    "Now, let's see what channels are present in the data. We simply have to take a loot at the `raw.ch_names` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index it as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.ch_names[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.ch_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel type of a specific channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.channel_type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_type = mne.channel_type(info=raw.info, idx=75)\n",
    "print('Channel #75 is of type:', channel_type)\n",
    "\n",
    "channel_type = mne.channel_type(info=raw.info, idx=320)\n",
    "print('Channel #320 is of type:', channel_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`raw.info['chs']` contains all the details about the sensors (type, locations, coordinate frame etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw.info['chs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raw.info['chs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['chs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['chs'][330]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to rename channels using the [`rename_channels()`](https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.rename_channels) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.rename_channels({\"EOG 061\": \"blink detector\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the sensor locations we can use [`plot_sensors()`](https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.plot_sensors) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_sensors(kind='topomap', ch_type='mag');  # default topomap\n",
    "raw.plot_sensors(ch_type='grad');\n",
    "raw.plot_sensors(kind=\"3d\", ch_type=\"all\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Working with sensor locations](https://mne.tools/stable/auto_tutorials/intro/40_sensor_locations.html#sphx-glr-auto-tutorials-intro-40-sensor-locations-py) tutorial describes how to read and plot sensor locations, and how MNE-Python handles physical locations of sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data from `Raw` objects\n",
    "\n",
    "To access the data, just use the `[]` syntax as to access any element of a list, dict etc. MNE-Python also returns an array of times (in seconds) corresponding to the requested samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start, stop = 0, 10\n",
    "data, times = raw[:, start:stop]  # fetch all channels and the first 10 time points\n",
    "print(data.shape)\n",
    "print(times.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract data in a given time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_freq = raw.info[\"sfreq\"]\n",
    "start_stop_seconds = np.array([11, 13])\n",
    "start_sample, stop_sample = (start_stop_seconds * sampling_freq).astype(int)\n",
    "channel_index = 0\n",
    "raw_selection = raw[channel_index, start_sample:stop_sample]\n",
    "print(raw_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get all data you can use the `get_data()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw.get_data()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing raw data\n",
    "\n",
    "Note : we will use the QT backend from matplotlib that will open a separate window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig = raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = raw.copy().pick_types(meg=False, eeg=True).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_fif(raw_fname, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_beta = raw.copy().filter(l_freq=13, h_freq=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(raw_beta.info)  # note the update of raw.info['lowpass'] and raw.info['highpass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_beta.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_beta.filter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Plot the 10 first seconds of the stimutation channel `STI 014` just using matplotlib.\n",
    "\n",
    "Tips:\n",
    "\n",
    "- Find the channel index using `raw.ch_names.index('STI 014')`\n",
    "- Get the data for this channel\n",
    "- Plot it using `plt.plot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Define and read epochs\n",
    "\n",
    "Let us now see how events are represented and used in MNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, extract events.\n",
    "The [`sample`](https://mne.tools/stable/documentation/datasets.html#sample-dataset) dataset includes experimental events recorded on stim channel `STI 014`. The events are parsed from this channel using [`mne.find_events()`](https://mne.tools/stable/generated/mne.find_events.html#mne.find_events) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events = mne.find_events(raw, stim_channel='STI 014', verbose=True)\n",
    "print(events.shape)\n",
    "print(type(events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LA - 1 - Response to left-ear auditory stimulus \\\n",
    "RA - 2 - Response to right-ear auditory stimulus \\\n",
    "LV - 3 - Response to left visual field stimulus \\\n",
    "RV - 4 - Response to right visual field stimulus \\\n",
    "smiley - 5 - Response to the smiley face \\\n",
    "button - 32 - Response triggered by the button press"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(events[:5])  # events is a 2d array, (time, previous, trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(events[events[:, 2] == 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = mne.viz.plot_events(events, sfreq=raw.info['sfreq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create an event Python dictionary to keep track of which Event ID corresponds to which experimental condition. The dictionary will be used to extract epochs from continuous data. The dictionary keys can contain `/` for grouping of sub-conditions. For example, if we want to pool all auditory trials, instead of merging Event IDs 1 and 2 using the `merge_events()` function, we can request for 'auditory' to select all epochs with Event IDs 1 and 2; requesting 'left' trials will select all epochs with Event IDs 1 and 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = {\"visual/left\": 3, \"visual/right\": 4,\n",
    "            \"auditory/left\": 1, \"auditory/right\": 2}\n",
    "\n",
    "fig = mne.viz.plot_events(events, sfreq=raw.info['sfreq'], event_id=event_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The events can be visualized together with the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(\n",
    "    events=events,\n",
    "    start=5,\n",
    "    duration=10,\n",
    "    color=\"gray\",\n",
    "    event_color={1: \"r\", 2: \"g\", 3: \"b\", 4: \"m\", 5: \"y\", 32: \"k\"},\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create epochs\n",
    "\n",
    "In MNE-Python [`Epochs`](https://mne.tools/stable/generated/mne.Epochs.html#mne.Epochs) objects are a data structure for representing and analyzing equal-duration trials of the M/EEG signal. Epochs are most often used to represent data that is time-locked to repeated experimental events (such as stimulus onsets or subject button presses), but can also be used for storing sequential or overlapping frames of a continuous signal (e.g., for analysis of resting-state activity). \\\n",
    "Inside an Epochs object, the data are stored in an array of shape `(n_epochs, n_channels, n_times)`. \n",
    "\n",
    "First, define epochs parameters: start, stop, and baseline period of the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = -0.2  # start of each epoch (200ms before the trigger)\n",
    "tmax = 0.5   # end of each epoch (500ms after the trigger)\n",
    "baseline = (None, 0)  # from the first time instant to the trigger pulse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define peak-to-peak (amplitude range) rejection parameters for gradiometers, magnetometers, and EOG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject = dict(grad=4000e-13, mag=4e-12, eog=150e-6)  # this can be highly data dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we select MEG and EOG channels\n",
    "picks_meg = mne.pick_types(raw.info, meg=True, eeg=False, eog=True,\n",
    "                           stim=False, exclude='bads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True,\n",
    "                    picks=picks_meg, baseline=baseline,\n",
    "                    reject=reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove bad epochs based on the `reject` parameter we passed to `Epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.drop_bad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how epochs were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epochs.plot_drop_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the data of some epochs use the [`get_data()`](https://mne.tools/stable/generated/mne.Epochs.html#mne.Epochs.get_data) method. \\\n",
    "`epochs_data` is a 3D array of dimension n_epochs x n_channels x n_time_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_data = epochs.get_data()\n",
    "type(epochs_data), epochs_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Epochs\n",
    "\n",
    "See [this page](https://mne.tools/stable/auto_tutorials/epochs/20_visualize_epochs.html) for options on how to visualize epochs. \\\n",
    "The `Epochs` object can be visualized (and browsed interactively) using its [`plot()`](https://mne.tools/stable/generated/mne.Epochs.html#mne.Epochs.plot) method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot(n_epochs=10, events=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above we can see heartbeat artifacts in the magnetometer channels, so before we continue let’s load ECG projectors from disk and apply them to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_proj_file = data_path / \"MEG\" / \"sample\" / \"sample_audvis_ecg-proj.fif\"\n",
    "ecg_projs = mne.read_proj(ecg_proj_file)\n",
    "epochs.add_proj(ecg_projs)\n",
    "epochs.apply_proj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convenient way to visualize many epochs simultaneously is to plot them as an image map, with each row of pixels in the image representing a single epoch, the horizontal axis representing time, and each pixel’s color representing the signal value at that time sample for that epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = epochs['auditory'].plot_image(combine='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to plot spectral power estimates across sensors as a scalp topography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = epochs[\"visual/right\"].compute_psd()\n",
    "bands = {\"10 Hz\": 10, \"15 Hz\": 15, \"20 Hz\": 20, \"10-20 Hz\": (10, 20)}\n",
    "spectrum.plot_topomap(bands=bands, vlim=\"joint\", ch_type=\"grad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average the epochs to get the evoked response (ERF/ERP)\n",
    "\n",
    "[`Evoked`](https://mne.tools/stable/generated/mne.Evoked.html#mne.Evoked) objects typically store M/EEG signals that have been averaged over multiple epochs, which is a common technique for estimating stimulus-evoked activity. The data in an `Evoked` object are stored in an array of shape `(n_channels, n_times)`. \\\n",
    "We already have the `Epochs` object, so we can simply use its `average` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evoked = epochs.average()\n",
    "print(evoked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information about the baseline period of `Epochs` is transferred to derived `Evoked` objects to maintain provenance as you process your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Epochs baseline: {epochs.baseline}\")\n",
    "print(f\"Evoked baseline: {evoked.baseline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = evoked.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This created an average across **all** conditions. Let's now estimate evoked responses for **individual** conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(event_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epochs['auditory/left'].average().plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `plot()` methods for [`Raw`](https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.plot), [`Epochs`](https://mne.tools/stable/generated/mne.Epochs.html#mne.Epochs.plot) and [`Evoked`](https://mne.tools/stable/generated/mne.Evoked.html#mne.Evoked.plot) objects, has many parameters for customizing the plot output, such as color-coding channel traces by scalp location, or plotting the global field power alongside the channel traces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing and indexing epochs by condition\n",
    "\n",
    "Epochs can be indexed by integers or slices to select a subset of epochs but also with strings to select by conditions `epochs[condition]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember `/` serves as a grouping operator. To calculate the evoked response across **all** \"left\" stimulations, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epochs['left'].average().plot(spatial_colors=True);  # note the legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember ...\n",
    "event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[0]  # first epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[:10]  # first 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['visual/left']  # epochs for the left visual condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['visual']  # epochs for the visual condition (either left or right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['left']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In event_id, `/` selects conditions in a hierarchical way, e.g. here, \"auditory\" vs. \"visual\", \"left\" vs. \"right\", and MNE can select them individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_auditory_left = epochs['auditory/left'].average().pick_types(meg='grad')\n",
    "evoked_auditory_left.crop(None, 0.2) # Beginning of evoked until 0.2s after stimulus onset.\n",
    "fig = evoked_auditory_left.plot(spatial_colors=True)\n",
    "fig = evoked_auditory_left.plot(spatial_colors=True, gfp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interactive session, the butterfly plots seen above can be click-dragged to select a time region, which will pop up a map of the average field distribution over the scalp for the selected time span."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Topographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scalp topographies at specific times or time spans can be also generated by using the [`plot_topomap()`](https://mne.tools/stable/generated/mne.Evoked.html#mne.Evoked.plot_topomap) method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = evoked.plot_topomap(ch_type='mag', times=[0.05, 0.1, 0.15])\n",
    "fig = evoked.plot_topomap(ch_type='grad', times=[0.05, 0.1, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "times = np.linspace(0.05, 0.15, 5)\n",
    "for ch_type in ('mag', 'grad'):\n",
    "    fig = evoked.plot_topomap(times=times, ch_type=ch_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to pass different time durations to average over for each time point. Passing a value of None will disable averaging for that time point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_durations = [0.01, 0.02, 0.03, None, None]\n",
    "fig = evoked.plot_topomap(\n",
    "    ch_type=\"mag\", times=times, average=averaging_durations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint plots combine butterfly plots with scalp topographies, and provide an excellent first-look at evoked data; by default, topographies will be automatically placed based on peak finding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = evoked.plot_joint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But of course, you can also specify custom time points for the topomaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = evoked.plot_joint(times=[0.1, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize topomaps for all experimental conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for condition in event_id:\n",
    "    fig = epochs[condition].average().plot_topomap(times=[0.1, 0.15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a contrast:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function [`combine_evoked()`](https://mne.tools/stable/generated/mne.combine_evoked.html#mne.combine_evoked) computes a weighted sum of the `Evoked` objects given to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked1 = epochs['auditory/left'].average()\n",
    "evoked2 = epochs['auditory/right'].average()\n",
    "\n",
    "contrast = mne.combine_evoked([evoked1, evoked2], weights=[1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this combines evokeds taking into account the number of averaged epochs (to scale the noise variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(evoked1.nave)  # average of 55 epochs\n",
    "print(evoked2.nave)  # average of 61 epochs\n",
    "print(contrast.nave)  # average of 116 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = evoked1.plot_joint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "- Extract Epochs restricted to magnetometers on unfiltered data (`sample_audvis_raw.fif`)\n",
    "- Construct epochs with a whole-epoch baseline. Then, high-pass filter raw data with a 1 Hz cutoff, construct epochs from that. Compare the resulting Evokeds (filter vs. baseline)\n",
    "- Plot the difference between all *visual* and all *auditory* stimulus presentations\n",
    "- Recompute everything for EEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> For more details look at the following tutorials: <br>\n",
    "    <a href=\"https://mne.tools/stable/auto_tutorials/raw/index.html\" target=\"_blank\">Working with continuous data </a> <br>\n",
    "    <a href=\"https://mne.tools/stable/auto_tutorials/epochs/index.html\" target=\"_blank\">Segmenting continuous data into epochs</a> <br>\n",
    "    <a href=\"https://mne.tools/stable/auto_tutorials/evoked/index.html\" target=\"_blank\">Estimating evoked responses</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d1899d3d453529ab54a548c453eb03872168ef6a9900e12952b62a455030e12"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
