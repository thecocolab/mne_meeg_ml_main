{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)\n",
    "\n",
    "Authors: Martin Billinger, Modified by Annalisa Pascarella, Vanessa Hadid\n",
    "\n",
    "Decoding of motor imagery applied to EEG data decomposed using CSP.\n",
    "Here the classifier is applied to features extracted on CSP filtered signals.\n",
    "\n",
    "See http://en.wikipedia.org/wiki/Common_spatial_pattern and [1]\n",
    "\n",
    "The EEGBCI dataset is documented in [2]\n",
    "The data set is available at PhysioNet [3]\n",
    "\n",
    "[1] Zoltan J. Koles. The quantitative extraction and topographic mapping\n",
    "    of the abnormal components in the clinical EEG. Electroencephalography\n",
    "    and Clinical Neurophysiology, 79(6):440--447, December 1991.\n",
    "\n",
    "[2] Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N.,\n",
    "    Wolpaw, J.R. (2004) BCI2000: A General-Purpose Brain-Computer Interface\n",
    "    (BCI) System. IEEE TBME 51(6):1034-1043\n",
    "\n",
    "[3] Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG,\n",
    "    Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000) PhysioBank,\n",
    "    PhysioToolkit, and PhysioNet: Components of a New Research Resource for\n",
    "    Complex Physiologic Signals. Circulation 101(23):e215-e220\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import MNE for EEG data processing and analysis, along with NumPy for numerical operations and Matplotlib for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "from mne.channels import read_layout\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load EEG data from the EEGBCI project for specific runs and subjects, which involves motor imagery tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters and read data\n",
    "tmin, tmax = -1., 4.\n",
    "subject = 1\n",
    "runs = [6, 10, 14]\n",
    "\n",
    "raw_fnames = eegbci.load_data(subject, runs)\n",
    "raw_fnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_files = [read_raw_edf(f, preload=True) for f in raw_fnames]\n",
    "raw = concatenate_raws(raw_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set channel locations to plot topographies with the montage\n",
    "from mne.channels import make_standard_montage\n",
    "raw.rename_channels(lambda x: x.strip('.'))\n",
    "montage = make_standard_montage('standard_1005')\n",
    "raw.set_montage(montage, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.annotations.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig = raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# strip channel names of \".\" characters\n",
    "raw.rename_channels(lambda x: x.strip('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Band-pass filtering is crucial to isolate the frequency bands relevant to motor tasks, typically within the 7-30 Hz range.\n",
    "Events related to motor imagery (e.g., imagining moving hands vs. feet) are extracted here. This step is critical for defining the time windows for epoch extraction. Apply a band-pass filter to the raw data to focus on frequencies between 7 and 30 Hz, which are relevant for analyzing motor tasks.\n",
    "Extract events from the annotations within the raw data, which denote different motor imagery tasks such as imagining moving hands vs. feet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply band-pass filter\n",
    "raw.filter(7., 30., method='iir')\n",
    "\n",
    "# events = find_events(raw, shortest_event=0, stim_channel='STI 014', verbose=True)\n",
    "events, _ = mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Events related to motor imagery (e.g., imagining moving hands vs. feet) are extracted here. This step is critical for defining the time windows for epoch extraction.\n",
    "Extract events from the annotations within the raw data, which denote different motor imagery tasks such as imagining moving hands vs. feet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = dict(hands=2, feet=3)\n",
    "\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                       exclude='bads')\n",
    "\n",
    "# Read epochs (train will be done only between 1 and 2s)\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                    baseline=None, preload=True)\n",
    "epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "labels = epochs.events[:, -1] - 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epochs['feet'].average().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Classifiers\n",
    "\n",
    "**Linear discrimant analysis (LDA)** is used to distinguish between different motor imagery tasks using the features extracted by CSP. LDA works well when the data is approximately normally distributed and the classes are linearly separable.\n",
    "\n",
    "**Logistic Regression**: This model could also be employed as it provides probabilistic outputs and is effective  in binary classification problems. Logistic regression is particularly useful if you are interested in measuring the uncertainty of predictions or if the classes are not perfectly linearly separable.\n",
    "\n",
    "**Support Vector Machine (SVM)**: SVM can be another excellent choice, especially with non-linear kernels (like RBF), when the decision boundaries between classes are not linear. SVMs are known for their effectiveness in high-dimensional spaces, such as those often encountered in EEG data analysis.\n",
    "\n",
    "**Random Forest**: This ensemble method, which operates by building multiple decision trees and voting on the most  popular output class, is robust to overfitting and can handle various types of data including non-linear relationships. Random Forests can also provide insights into feature importance, which can be valuable for interpreting the features extracted by CSP.\n",
    "\n",
    "Each of these classifiers can be integrated with CSP features to potentially improve classification accuracy and robustness, depending on the specific characteristics of the EEG data and the task requirements.\n",
    "\n",
    "### CSP parameters\n",
    "  \n",
    "**n_components**: int, optional (default=4)\n",
    "The number of components to use for CSP. This parameter determines the number of spatial filters to construct. \n",
    "Each component will correspond to a pattern which maximizes the variance for one class while minimizing it for the other.\n",
    "Essentially, fewer components focus on the most discriminative spatial patterns, while more components can capture more complex patterns but may include noise.\n",
    "\n",
    "**reg**: None | float | str, optional (default=None)\n",
    "This parameter is used to regularize the covariance matrices of the signal.\n",
    "Regularization can help improve the stability and generalization of the CSP patterns, especially when the number of samples is small.\n",
    "If set to None, no regularization is applied. You can also specify a float value as the shrinkage coefficient directly or use a string to specify a method of automatic shrinkage selection such as 'ledoit_wolf' (Ledoit-Wolf estimator) or 'oas' (Oracle Approximating Shrinkage).\n",
    "\n",
    "**log**: bool, optional (default=True)\n",
    "Specifies whether to apply log transformation to the variances obtained by the CSP. \n",
    "Applying log transformation typically improves the classification by normalizing the distribution and making the features more Gaussian-like. \n",
    "This is generally useful because many classifiers, especially linear models, assume that the input data is normally distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Assemble a classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "csp = CSP(n_components=4, reg=None, log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.get_data().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up cross-validation to ensure the model generalizes well to new data. \n",
    "This involves creating multiple training and testing splits to validate the stability and accuracy of the classifier.\n",
    "Additionally, other cross-validation techniques such as KFold or StratifiedKFold can be used depending on the dataset characteristics and the specific requirements of the study.\n",
    "\n",
    "The seed of the pseudo random number generator to use when shuffling the data. \n",
    "If int, random_state is the seed used by the random number generator; \n",
    "If RandomState instance, random_state is the random number generator; \n",
    "If None, the random number generator is the RandomState instance used by `np.random`.\n",
    "Specifying a fixed `random_state` ensures that the splits you generate are reproducible. \n",
    "Changing this value will result in different shuffles, which can alter the cross-validation results. \n",
    "This parameter is especially important in scenarios where exact reproducibility is required for debugging or comparative model evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a monte-carlo cross-validation generator (reduce variance):\n",
    "cv = ShuffleSplit(10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "X = epochs.get_data()\n",
    "X_train = epochs_train.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn Pipeline with cross_val_score function\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = Pipeline([('CSP', csp), ('LDA', lda)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Evaluating Classifier Performance\n",
    "\n",
    "The default scoring metric for `cross_val_score` is the classifier’s accuracy, which measures the proportion of correctly predicted instances. However, other metrics can also be specified using the `scoring` parameter:\n",
    "\n",
    "- 'accuracy': Measures the proportion of correctly predicted instances.\n",
    "- 'precision': Measures the accuracy of positive predictions.\n",
    "- 'recall': Measures the ability of the classifier to find all the positive samples.\n",
    "- 'f1': A weighted average of precision and recall.\n",
    "- 'roc_auc': Area under the ROC curve, useful for evaluating the performance across all possible classification thresholds.\n",
    "\n",
    "These metrics can provide a more nuanced view of the classifier's performance, particularly in datasets where class imbalance might affect the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, X_train, labels, cv=cv, n_jobs=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance\n",
    "`class_balance` calculates the proportion of the most frequent class in the dataset. \n",
    "This value is used to gauge the chance level of classification accuracy, which helps in evaluating whether the classifier is performing meaningfully better than just guessing the most frequent class.\n",
    "- If `labels == labels[0]` returns True, it counts how often the first label occurs compared to others.\n",
    "- The calculation of `max(class_balance, 1. - class_balance)` ensures that the balance score reflects the majority class, providing a baseline accuracy that a naive classifier would achieve by always predicting the majority class. If the classes are perfectly balanced, this value would be 0.5.\n",
    "\n",
    "*See Thölke et al.2023, Neuroimage.*\n",
    "\n",
    "### CSP Pattern Visualization\n",
    "After fitting the CSP, the `plot_patterns` function visualizes the spatial filters that have been learned.\n",
    "These filters highlight the regions of the brain that contribute most to distinguishing between the classes based on the EEG signals. The patterns are plotted with labels corresponding to their channel type ('eeg'),and the units are arbitrary units (AU), with the size parameter controlling the scale of the plot. Visualizing these patterns can help in understanding which areas of the brain are most active in differentiating between the tasks being classified (e.g., imagining moving hands vs. feet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the results\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n",
    "\n",
    "# plot CSP patterns estimated on full data for visualization\n",
    "csp.fit_transform(X, labels)\n",
    "\n",
    "fig = csp.plot_patterns(epochs.info, ch_type='eeg',\n",
    "                  units='Patterns (AU)', size=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at performance over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window Analysis in EEG Data\r\n",
    "\r\n",
    "In this section, we implement a sliding window analysis to evaluate how classification accuracy evolves over time, providing insights into the dynamic changes in brain activity during motor imagery tasks. This technique is essential for understanding temporal aspects of the EEG data, particularly in tasks where brain activity patterns change rapidly.\r\n",
    "\r\n",
    "### What is a Sliding Window Analysis?\r\n",
    "\r\n",
    "A sliding window analysis involves moving a small \"window\" across the data to analyze it in chunks over time. This method allows us to assess the classifier's performance continuously as opposed to a static overall measurement. It is particularly useful for EEG data where the state of the brain can change significantly in a short period.\r\n",
    "\r\n",
    "### Parameter Explanation:\r\n",
    "- **Sampling Frequency (`sfreq`)**: This indicates the number of data samples recorded per second, which determines the temporal granularity of our analysis.\r\n",
    "- **Window Length (`w_length`)**: This is the duration of each window, set to 0.5 seconds in this study. This length is chosen to ensure each window captures enough data to provide reliable insights while maintaining the ability to detect rapid changes.\r\n",
    "- **Window Step (`w_step`)**: This defines the increment by which the window moves across the data. A smaller step size of 0.1 seconds allows for a more detailed and granular analysis, giving us a finer understanding of when changes occur.\r\n",
    "- **Window Start Points (`w_start`)**: These are the initial points for each window throughout the data, calculated to ensure comprehensive coverage without overlapping beyond the data's duration.\r\n",
    "\r\n",
    "### Why Use Sliding Windows?\r\n",
    "Sliding windows are advantageous for studying EEG data because they allow researchers to:\r\n",
    "- **Track Changes Over Time**: By analyzing the data in consecutive segments, researchers can observe how the patterns of brain activity evolve.\r\n",
    "- **Capture Dynamic Brain Activity**: Motor imagery tasks can induce quick shifts in neural activity. Sliding windows help in capturing these changes that might be missed in a static or overall analysis.\r\n",
    "- **Enhance Statistical Power**: Analyzing multiple small segments can sometimes offer more nuanced insights into the data, increasing the reliability of the results.\r\n",
    "\r\n",
    "The results from this method will provide a time-resolved plot of classification accuracy, illustrating how well the classifier can distinguish between different motor imagery tasks at various points during the EEG session.\r\n",
    "he EEG session.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = raw.info['sfreq']\n",
    "w_length = int(sfreq * 0.5)   # running classifier: window length\n",
    "w_step = int(sfreq * 0.1)  # running classifier: window step size\n",
    "w_start = np.arange(0, X.shape[2] - w_length, w_step)\n",
    "\n",
    "scores_windows = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X, labels):\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    XX_train = csp.fit_transform(X_train[train_idx], y_train)\n",
    "    XX_test = csp.transform(X_train[test_idx])\n",
    "\n",
    "    # fit classifier\n",
    "    lda.fit(XX_train, y_train)\n",
    "\n",
    "    # running classifier: test classifier on sliding window\n",
    "    score_this_window = []\n",
    "    for n in w_start:\n",
    "        XX_test = csp.transform(X[test_idx][:, :, n:(n + w_length)])\n",
    "        score_this_window.append(lda.score(XX_test, y_test))\n",
    "    scores_windows.append(score_this_window)\n",
    "\n",
    "# Plot scores over time\n",
    "w_times = (w_start + w_length / 2.) / sfreq + epochs.tmin\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(w_times, np.mean(scores_windows, 0), label='Score')\n",
    "plt.axvline(0, linestyle='--', color='k', label='Onset')\n",
    "plt.axhline(0.5, linestyle='-', color='k', label='Chance')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('classification accuracy')\n",
    "plt.title('Classification score over time')\n",
    "plt.legend(loc='lower right')\n",
    "fig = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "The following exercises are designed to enhance understanding and hands-on experience with EEG data analysis using CSP:\n",
    "\n",
    "- **CSP Parameter Exploration:** Explore how different CSP parameters (n_components, reg, log) affect the model's performance. Adjust these parameters and visualize their impact on classification accuracy.\n",
    "- **Classifier Comparison:** Investigate the use of different classifiers. Replace LDA with a Random Forest classifier and compare the classification performance. Adjust data preprocessing if necessary.\n",
    "- **Cross-Validation Strategies:** Investigate different cross-validation strategies and scoring methods to understand their influence on model stability and accuracy. Try using KFold and StratifiedKFold.\n",
    "- **Further Reading:** For more information on CSP and its applications in EEG analysis, see [MNE's CSP documentation](https://mne.tools/stable/generated/mne.decoding.CSP.html#mne.decoding.CSP)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d1899d3d453529ab54a548c453eb03872168ef6a9900e12952b62a455030e12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
